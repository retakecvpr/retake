### model
model_name_or_path: saves/baselines/Qwen2-VL-72B-Instruct-128k
flash_attn: fa2
infer_dtype: bfloat16
infer_backend: vllm

### method
stage: sft
vllm_maxlen: 131072
finetuning_type: full
template: qwen2_vl
